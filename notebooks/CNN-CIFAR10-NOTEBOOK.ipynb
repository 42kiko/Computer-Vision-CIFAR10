{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üß† CIFAR-10 CNN Experiments\n",
    "\n",
    "This notebook trains a convolutional neural network (CNN) on the CIFAR-10 dataset\n",
    "using the utility functions from `utils.py`. The goal is to achieve strong predictive\n",
    "performance with a clean, modular setup that runs well on a MacBook Air M3.\n"
   ],
   "id": "5ad7e33970e1f4e4"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1Ô∏è‚É£ Setup and imports\n",
    "\n",
    "In this section we import the utilities and configure a few global settings\n",
    "such as the random seed, batch size and number of epochs.\n"
   ],
   "id": "33e345da581fd48b"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from src.utils import (\n",
    "    set_global_seed,\n",
    "    load_cifar10,\n",
    "    create_data_augmentation,\n",
    "    build_cifar10_cnn,\n",
    "    compile_model,\n",
    "    train_model,\n",
    "    CLASS_NAMES,\n",
    "    CLASS_NAMES_EMOJI,\n",
    "    NUM_CLASSES,\n",
    "    save_fig,\n",
    "    save_model_with_history,\n",
    "    upscale_and_super_sharpen\n",
    ")\n",
    "\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Ensure reproducibility\n",
    "set_global_seed(42)\n",
    "\n",
    "# High-level training configuration\n",
    "LEARNING_RATE: float = 1e-3\n",
    "BATCH_SIZE: int = 64\n",
    "EPOCHS: int = 30  # adjust down if you want faster experiments\n"
   ],
   "id": "5f99bfc0a6537810",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2Ô∏è‚É£ Load and inspect CIFAR-10 üì•\n",
    "\n",
    "Here we load the CIFAR-10 dataset using the helper from `utils.py` and\n",
    "briefly inspect shapes and class distribution.\n"
   ],
   "id": "419f947bb0506e47"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load CIFAR-10 data (raw uint8 images, normalization is handled in the model)\n",
    "data = load_cifar10(normalize=False)\n",
    "\n",
    "print(\"Training images:\", data.x_train.shape, data.x_train.dtype)\n",
    "print(\"Test images:    \", data.x_test.shape, data.x_test.dtype)\n",
    "\n",
    "# Basic class distribution in the training set\n",
    "class_counts = np.bincount(data.y_train, minlength=len(CLASS_NAMES))\n",
    "for idx, (name, count) in enumerate(zip(CLASS_NAMES, class_counts)):\n",
    "    print(f\"Class {idx:2d} ({name:10s}): {count}\")\n"
   ],
   "id": "16b38e63a3028e1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìä Class distribution plot\n",
    "\n",
    "The bar chart below shows how many samples we have per class in the\n",
    "training split. CIFAR-10 is perfectly balanced, which is helpful for\n",
    "both accuracy and recall.\n"
   ],
   "id": "e9c3d5e673d5aeea"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig_class_dist = px.bar(\n",
    "    x=CLASS_NAMES_EMOJI,\n",
    "    y=class_counts,\n",
    "    title=\"CIFAR-10 training set class distribution\",\n",
    "    labels={\"x\": \"Class\", \"y\": \"Count\"},\n",
    ")\n",
    "fig_class_dist.update_layout(xaxis_tickangle=0)\n",
    "fig_class_dist.update_xaxes(tickfont=dict(size=28))\n",
    "fig_class_dist.show()\n",
    "\n",
    "\n",
    "save_fig(fig_class_dist, \"class_distribution\")"
   ],
   "id": "84ee69cf1abaadef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üñºÔ∏è Example images per class\n",
    "\n",
    "In this section, we visualize multiple example images for each CIFAR-10 class using Plotly.\n",
    "This helps to build an intuitive understanding of what the model will see during training\n",
    "and how the different classes look in practice."
   ],
   "id": "412feee2c2268af2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Number of example images to display per class\n",
    "EXAMPLES_PER_CLASS: int = 10  # you can increase this if you want\n",
    "\n",
    "rows = NUM_CLASSES\n",
    "cols = EXAMPLES_PER_CLASS\n",
    "\n",
    "fig = make_subplots(\n",
    "    rows=rows,\n",
    "    cols=cols,\n",
    "    horizontal_spacing=0.01,\n",
    "    vertical_spacing=0.01,\n",
    ")\n",
    "\n",
    "for class_idx, class_name in enumerate(CLASS_NAMES_EMOJI):\n",
    "    # Find indices of all images belonging to this class\n",
    "    class_indices = np.where(data.y_train == class_idx)[0]\n",
    "\n",
    "    if len(class_indices) == 0:\n",
    "        # This can happen if TRAIN_LIMIT is very small and some classes are missing\n",
    "        continue\n",
    "\n",
    "    # Randomly select up to EXAMPLES_PER_CLASS images\n",
    "    n_examples = min(EXAMPLES_PER_CLASS, len(class_indices))\n",
    "    selected_indices = np.random.choice(\n",
    "        class_indices,\n",
    "        size=n_examples,\n",
    "        replace=False,\n",
    "    )\n",
    "\n",
    "    for col_idx, img_idx in enumerate(selected_indices):\n",
    "        row = class_idx + 1\n",
    "        col = col_idx + 1\n",
    "\n",
    "        img = data.x_train[img_idx]\n",
    "        img_up = upscale_and_super_sharpen(img, scale=6)\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Image(z=img_up),\n",
    "            row=row,\n",
    "            col=col,\n",
    "        )\n",
    "\n",
    "        fig.update_xaxes(showticklabels=False, row=row, col=col)\n",
    "        fig.update_yaxes(showticklabels=False, row=row, col=col)\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title=dict(\n",
    "            text=class_name,\n",
    "            font=dict(size=30)\n",
    "        ),\n",
    "        row=class_idx + 1,\n",
    "        col=1,\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title=\"Example CIFAR-10 images per class\",\n",
    "    height=150 * rows,\n",
    "    width=150 * cols,\n",
    "    showlegend=False,\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "save_fig(fig, \"examples_per_class\")"
   ],
   "id": "684ee9ae81cd93cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3Ô∏è‚É£ Build and compile the CNN üß±\n",
    "\n",
    "We now create a reasonably strong CNN architecture with:\n",
    "\n",
    "- Data augmentation (random flips, rotations, zoom)\n",
    "- Convolutional blocks with Batch Normalization and ReLU\n",
    "- Max pooling and Dropout for downsampling and regularization\n",
    "- A dense classification head with Dropout before the softmax layer\n",
    "\n",
    "Compilation uses the Adam optimizer with a sensible learning rate for CIFAR-10.\n"
   ],
   "id": "c008e8bd581c1bb2"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Create data augmentation pipeline\n",
    "data_augmentation = create_data_augmentation()\n",
    "\n",
    "# Build model\n",
    "model = build_cifar10_cnn(\n",
    "    input_shape=data.x_train.shape[1:],\n",
    "    num_classes=len(CLASS_NAMES),\n",
    "    data_augmentation=data_augmentation,\n",
    ")\n",
    "\n",
    "# Compile model\n",
    "compile_model(model, learning_rate=LEARNING_RATE)\n",
    "\n",
    "model.summary()\n"
   ],
   "id": "db4e509ba4457d64",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4Ô∏è‚É£ Train the model üöÇ\n",
    "\n",
    "We train the model on the full CIFAR-10 training set with a small\n",
    "validation split to monitor generalization. Default callbacks from\n",
    "`train_model` use learning rate scheduling and early stopping\n",
    "to reach strong performance without excessive overfitting.\n"
   ],
   "id": "b0aadd38a06493fe"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "history = train_model(\n",
    "    model,\n",
    "    data.x_train,\n",
    "    data.y_train,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.1,\n",
    ")"
   ],
   "id": "8346bf173bba259f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# save model & history\n",
    "save_model_with_history(model, history, \"cifar10_main\")"
   ],
   "id": "fb80f8f71525bb6a",
   "outputs": [],
   "execution_count": null
  }
 ]
}
