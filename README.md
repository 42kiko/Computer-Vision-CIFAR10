# Computer Vision Project with CIFAR-10 Dataset ğŸ‘ï¸â€ğŸ—¨ğŸ–¥ï¸ï¸

This project trains and analyses a convolutional neural network (CNN) on the
[CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) image classification dataset.
The focus is not only on model accuracy, but also on **interpretability** through
rich visualisations and error analysis.

---

## ğŸ§  Model architecture

The core model is a compact CNN built with TensorFlow / Keras using:

- stacked convolutional blocks (Conv2D â†’ BatchNorm â†’ ReLU â†’ MaxPooling â†’ Dropout)
- a dense classification head with softmax over 10 classes

---
## ğŸ“‚ Project structure

The repository is organised as follows:

```text

Computer-Vision-CIFAR10/
â”œâ”€â”€ docs/                       # Interactive Plotly HTML exports (for GitHub Pages)
â”‚   â”œâ”€â”€ cifar10_acc.html
â”‚   â”œâ”€â”€ cifar10_avg_confidence_per_true_class.html
â”‚   â”œâ”€â”€ cifar10_confidence_hist.html
â”‚   â”œâ”€â”€ cifar10_confusion_matrix.html
â”‚   â”œâ”€â”€ cifar10_hard_prediction_grid.html
â”‚   â”œâ”€â”€ cifar10_loss.html
â”‚   â”œâ”€â”€ cifar10_misclassification_grid.html
â”‚   â”œâ”€â”€ cifar10_per_class_accuracy.html
â”‚   â”œâ”€â”€ cifar10_top_1_percent_correct_predictions.html
â”‚   â”œâ”€â”€ cifar10_top_1_percent_wrong_predictions.html
â”‚   â”œâ”€â”€ class_distribution.html
â”‚   â””â”€â”€ examples_per_class.html
â”‚
â”œâ”€â”€ models/                     # Saved Keras models
â”‚   â””â”€â”€ cifar10_main.keras
â”‚
â”œâ”€â”€ notebooks/                  # Jupyter notebooks (EDA and training)
â”‚   â”œâ”€â”€ CNN-CIFAR10-NOTEBOOK.ipynb
â”‚   â””â”€â”€ EDA.ipynb
â”‚
â”œâ”€â”€ plots/                      # Static PNG previews for README and index.html
â”‚   â”œâ”€â”€ cifar10_acc.png
â”‚   â”œâ”€â”€ cifar10_avg_confidence_per_true_class.png
â”‚   â”œâ”€â”€ cifar10_confidence_hist.png
â”‚   â”œâ”€â”€ cifar10_confusion_matrix.png
â”‚   â”œâ”€â”€ cifar10_hard_prediction_grid.png
â”‚   â”œâ”€â”€ cifar10_loss.png
â”‚   â”œâ”€â”€ cifar10_misclassification_grid.png
â”‚   â”œâ”€â”€ cifar10_per_class_accuracy.png
â”‚   â”œâ”€â”€ cifar10_top_1_percent_correct_predictions.png
â”‚   â”œâ”€â”€ cifar10_top_1_percent_wrong_predictions.png
â”‚   â”œâ”€â”€ class_distribution.png
â”‚   â””â”€â”€ examples_per_class.png
â”‚
â”œâ”€â”€ results/                    # Serialized training history and metrics
â”‚   â””â”€â”€ history_cifar10_main.json
â”‚
â”œâ”€â”€ src/                        # Reusable Python modules
â”‚   â””â”€â”€ utils.py
â”‚
â”œâ”€â”€ tests/                      # Unit tests
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ index.html                  # Landing page for GitHub Pages (interactive gallery)
â””â”€â”€ README.md                   # Project documentation (this file)

```


---

## ğŸŒ Interactive visualizations

All interactive Plotly figures are available on GitHub Pages:

ğŸ‘‰ **https://42kiko.github.io/Computer-Vision-CIFAR10/**

The gallery includes:

- dataset overview (class distribution, examples per class)  
- training dynamics (accuracy and loss)  
- confusion matrix and per-class accuracy  
- confidence analysis and detailed grids of correct / wrong predictions  

---

## ğŸ“Š Dataset overview

### ğŸ“¦ Class distribution

This plot shows how many training examples exist for each CIFAR-10 class.  
The dataset is roughly balanced, which is helpful for training the classifier.

Click the image to open the interactive Plotly version in your browser:

[![CIFAR-10 class distribution](plots/class_distribution.png)](https://42kiko.github.io/Computer-Vision-CIFAR10/docs/class_distribution.html "Open interactive Plotly version")

---

### ğŸ–¼ï¸ Examples per class

This grid visualises several example images for each class.  
It helps to build an intuitive understanding of what the model actually sees
and how visually similar some categories are.

Click the image to open the interactive Plotly version in your browser:

[![CIFAR-10 examples per class](plots/examples_per_class.png)](https://42kiko.github.io/Computer-Vision-CIFAR10/docs/examples_per_class.html "Open interactive Plotly version")

---

## ğŸ“ˆ Training & evaluation (summary)

In the notebooks and interactive plots you can explore:

- **Training curves**
  - Accuracy and loss over epochs for train and validation sets  
  - Used to check convergence and detect overfitting / underfitting  

- **Confusion matrix & per-class accuracy**
  - Shows which classes are recognised reliably  
  - Highlights pairs of classes that are frequently confused  

- **Confidence & error analysis**
  - Confidence distribution for correct vs wrong predictions  
  - Top 1 % most confident correct and wrong predictions  
  - â€œHard but correctâ€ edge cases and misclassification grids  

For full details, see the notebooks in `notebooks/` and the interactive
visualisations on the GitHub Pages dashboard linked above.